{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90584c98-9edc-4222-a153-a4a73bfee745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T01:45:08.001031Z",
     "iopub.status.busy": "2024-06-06T01:45:08.000177Z",
     "iopub.status.idle": "2024-06-06T01:45:23.125527Z",
     "shell.execute_reply": "2024-06-06T01:45:23.123787Z",
     "shell.execute_reply.started": "2024-06-06T01:45:08.000969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grad-cam\n",
      "  Downloading grad-cam-1.5.2.tar.gz (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.26.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from grad-cam) (9.5.0)\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (2.1.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (0.16.1+cu121)\n",
      "Collecting ttach (from grad-cam)\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.66.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.8.0.76)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from grad-cam) (3.7.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.8.2->grad-cam) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->grad-cam) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n",
      "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: grad-cam\n",
      "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.5.2-py3-none-any.whl size=38335 sha256=76ed2208e543e3895c7bb84329ce2a6f42cae98ee2526ddbcc5ace6550f968c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/25/dd/cf5dc1751e3d5b89ea4d877a61ba969939c78cf4223ace9c59\n",
      "Successfully built grad-cam\n",
      "Installing collected packages: ttach, grad-cam\n",
      "Successfully installed grad-cam-1.5.2 ttach-0.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63984f8b-8af4-4e21-b0c0-35f0fd3b78a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T01:55:05.320486Z",
     "iopub.status.busy": "2024-06-06T01:55:05.320007Z",
     "iopub.status.idle": "2024-06-06T01:55:10.959179Z",
     "shell.execute_reply": "2024-06-06T01:55:10.957225Z",
     "shell.execute_reply.started": "2024-06-06T01:55:05.320443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128, 64])\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - Can't parse 'dsize'. Expected sequence length 2, got 3\n>  - Can't parse 'dsize'. Expected sequence length 2, got 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 110\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Compute the Grad-CAM\u001b[39;00m\n\u001b[1;32m    109\u001b[0m targets \u001b[38;5;241m=\u001b[39m [ClassifierOutputTarget(\u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m--> 110\u001b[0m grayscale_cam \u001b[38;5;241m=\u001b[39m \u001b[43mcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Visualize the Grad-CAM\u001b[39;00m\n\u001b[1;32m    113\u001b[0m visualization \u001b[38;5;241m=\u001b[39m show_cam_on_image(input_tensor, grayscale_cam, use_rgb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_grad_cam/base_cam.py:186\u001b[0m, in \u001b[0;36mBaseCAM.__call__\u001b[0;34m(self, input_tensor, targets, aug_smooth, eigen_smooth)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aug_smooth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_augmentation_smoothing(input_tensor, targets, eigen_smooth)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigen_smooth\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_grad_cam/base_cam.py:110\u001b[0m, in \u001b[0;36mBaseCAM.forward\u001b[0;34m(self, input_tensor, targets, eigen_smooth)\u001b[0m\n\u001b[1;32m     99\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# In most of the saliency attribution papers, the saliency is\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# computed with a single target layer.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Commonly it is the last convolutional layer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# use all conv layers for example, all Batchnorm layers,\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# or something else.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m cam_per_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_cam_per_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigen_smooth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_multi_layers(cam_per_layer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_grad_cam/base_cam.py:143\u001b[0m, in \u001b[0;36mBaseCAM.compute_cam_per_layer\u001b[0;34m(self, input_tensor, targets, eigen_smooth)\u001b[0m\n\u001b[1;32m    141\u001b[0m     cam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_cam_image(input_tensor, target_layer, targets, layer_activations, layer_grads, eigen_smooth)\n\u001b[1;32m    142\u001b[0m     cam \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(cam, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscale_cam_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     cam_per_target_layer\u001b[38;5;241m.\u001b[39mappend(scaled[:, \u001b[38;5;28;01mNone\u001b[39;00m, :])\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cam_per_target_layer\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_grad_cam/utils/image.py:172\u001b[0m, in \u001b[0;36mscale_cam_image\u001b[0;34m(cam, target_size)\u001b[0m\n\u001b[1;32m    169\u001b[0m             img \u001b[38;5;241m=\u001b[39m zoom(np\u001b[38;5;241m.\u001b[39mfloat32(img), [\n\u001b[1;32m    170\u001b[0m                        (t_s \u001b[38;5;241m/\u001b[39m i_s) \u001b[38;5;28;01mfor\u001b[39;00m i_s, t_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape, target_size[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])])\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m             img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m    175\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(result)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - Can't parse 'dsize'. Expected sequence length 2, got 3\n>  - Can't parse 'dsize'. Expected sequence length 2, got 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2)\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2)\n",
    "        self.bn3 = nn.BatchNorm3d(128)\n",
    "\n",
    "        self.conv4 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=2)\n",
    "        self.bn4 = nn.BatchNorm3d(256)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc1 = nn.Linear(256, 512)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.pool1(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.pool2(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.pool3(self.conv3(x))))\n",
    "        x = F.relu(self.bn4(self.pool4(self.conv4(x))))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = CNN3D()\n",
    "model.load_state_dict(torch.load('3d_image_classification.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Define the target layer for Grad-CAM\n",
    "target_layers = [model.conv4]\n",
    "\n",
    "# Create the Grad-CAM object\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "# Load the input 3D image\n",
    "# Load the NIfTI file\n",
    "output_dir = os.path.join(os.getcwd(), \"MosMedData\")\n",
    "input_nifti_path = os.path.join(output_dir, \"CT-23\", \"study_0939.nii.gz\")\n",
    "output_nifti_path =os.path.join(output_dir, \"output\", \"study_0939.nii.gz\")\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    scan = nib.load(filepath)\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "def normalize(volume):\n",
    "    min, max = -1000, 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "def resize_volume(img):\n",
    "    desired_depth, desired_width, desired_height = 64, 128, 128\n",
    "    current_depth, current_width, current_height = img.shape[-1], img.shape[0], img.shape[1]\n",
    "    depth_factor, width_factor, height_factor = current_depth / desired_depth, current_width / desired_width, current_height / desired_height\n",
    "    depth_factor, width_factor, height_factor = 1 / depth_factor, 1 / width_factor, 1 / height_factor\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "def process_scan(path):\n",
    "    volume = read_nifti_file(path)\n",
    "    volume = normalize(volume)\n",
    "    volume = resize_volume(volume)\n",
    "    return volume\n",
    "\n",
    "\n",
    "# Reshape the data\n",
    "data = process_scan(input_nifti_path)\n",
    "# data = data.reshape((data.shape[0], data.shape[1], data.shape[2]))\n",
    "## Convert to Torch Tensor\n",
    "# input_tensor = torch.from_numpy(data)\n",
    "input_tensor = torch.tensor(data).unsqueeze(0).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "print(input_tensor.shape)\n",
    "\n",
    "# Compute the Grad-CAM\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "# Visualize the Grad-CAM\n",
    "visualization = show_cam_on_image(input_tensor, grayscale_cam, use_rgb=True)\n",
    "\n",
    "# Save the visualization\n",
    "# torch.save(visualization, 'grad_cam_visualization.pth')\n",
    "plt.imshow(visualization)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
